/*
   processFolder.js 
*/
import fs from 'fs/promises';
import path from 'path';
import { db } from './sqlite.js'
import { analyzeFile, hashFile, walk, SQL_create_table, SQL_insert, SQL_update, SQL_create_table_fs, writeAudit } from './utils.js'

const BATCH_SIZE = process.env.BATCH_SIZE || 100;

let batch = [];                     // Pending records
let processedCount = 0;             // Files processed
let skippedCount = 0;               // Files skipped

// ğŸ§­ Get folder path from command-line argument
const args = process.argv.slice(2);

// ğŸ†˜ Help flag
if (args.includes('--help') || args.includes('-h')) {
  console.log(`
Usage: npm run process -- [folderPath]

For example: 
   npm run process -- D:\\Photos

If no folderPath is specified, the default is "./samples"

Options:
  -h, --help     Show this help message
`);
  process.exit(0);
}

// ğŸ“ Default to D:\ if no argument is given
const ROOT_FOLDER = args[0] || './samples';

// ğŸ“£ Show which folder will be scanned
console.log(`ğŸ“‚ Scanning folder: ${ROOT_FOLDER}`);

// ğŸ§¾ Flush batch into database, handle constraint violations
function flushBatch(db, insert, update) {
  if (batch.length === 0) return;

  try {
    const transaction = db.transaction(() => {
      for (const item of batch) {
        try {
          insert.run(
            item.fileName,
            item.fullPath,
            item.fileFormat,
            item.fileSize,
            item.isTextFile ? 1 : 0, 
            item.content, 
            item.hash,
            item.indexedAt,
            item.createdAt,
            item.modifiedAt
          );
          processedCount++;
        } catch (err) {
          console.warn('âš ï¸ Constraint hit for:', item.fullPath);
          if (err.code === 'SQLITE_CONSTRAINT') {
            update.run(item.fullPath);
            skippedCount++;
          } else {
            throw err;
          }
        }
      }
    });

    transaction(); // execute the transaction
    console.log(`ğŸ“¦ Batch flushed: ${batch.length} items`);
    batch = [];
  } catch (err) {
    console.error('âš ï¸ Error during flushBatch:', err.message);
  }
}

// ğŸ§¬ Process individual file and add to batch
async function processFile(filePath, db, insert, update) {
  const now = new Date();

  try {
    const stat = await fs.stat(filePath);
    //const hash = await hashFile(filePath);
    const { hash, isTextFile, content } = await analyzeFile(filePath)
    const fileName = path.basename(filePath);
    const fileFormat = path.extname(filePath).slice(1).toLowerCase();
    const fileSize = stat.size;
    const indexedAt = now.toISOString();
    const createdAt = stat.birthtime.toISOString();
    const modifiedAt = stat.mtime.toISOString();

    if (!hash) {
      console.warn(`âš ï¸ Warning ${filePath} â€” hash is null`);
    }    
    batch.push({
      fileName,
      fullPath: filePath,
      fileFormat,
      fileSize,
      isTextFile, 
      content, 
      hash,
      indexedAt, 
      createdAt,
      modifiedAt
    });

    if (batch.length >= BATCH_SIZE) {
      flushBatch(db, insert, update);
    }
  } catch (err) {
    console.error(`âš ï¸ Error processing ${filePath}:`, err.message);
  }
}

// ğŸ§± Main ritual: setup DB, scan folder, insert records
async function main() {
  await fs.mkdir('./data', { recursive: true });

  // ğŸ§¾ Create tables
  db.exec(SQL_create_table);
  
  // ğŸ§¾ Prepare insert statement 
  const insert = db.prepare(SQL_insert);

  // ğŸ§¾ Prepare update statement 
  const update = db.prepare(SQL_update);

  // Write audit
  writeAudit(db, 'scanFolder', ROOT_FOLDER);
  writeAudit(db, 'mode', 'single');
  writeAudit(db, 'batchSize', BATCH_SIZE);
  
  const startTime = new Date(); // âœ… creates a Date object
  writeAudit(db, 'startTime', startTime.toISOString());

  // Start running here... 
  for await (const filePath of walk(ROOT_FOLDER)) {
    await processFile(filePath, db, insert, update);
  }
  /*
  // JavaScript does this under the hood:

  const iterator = walk(ROOT_FOLDER)[Symbol.asyncIterator]();
  let result = await iterator.next();
  while (!result.done) {
    const filePath = result.value;
    await processFile(filePath, db, insertStmt, updateStmt);
    result = await iterator.next();
  }
  */

  // ğŸ§º Flush remaining records to DB
  flushBatch(db, insert, update);   
  
  // Write audit
  const endTime = new Date(); // âœ… creates a Date object
  const elapsed = ((endTime - startTime) / 1000).toFixed(2);
  
  writeAudit(db, 'endTime', endTime.toISOString());
  writeAudit(db, 'elapsedTime', elapsed);
  writeAudit(db, 'filesProcessed', processedCount);
  writeAudit(db, 'filesSkipped',  skippedCount);

  // ğŸ§¾ Create tables for full text search
  db.exec(SQL_create_table_fs);

  db.close();               // ğŸ”š Close database connection
  
  // ğŸ§® Final report
  console.log(`\nâœ… Scan complete.`);
  console.log(`â±ï¸ Elapsed time: ${elapsed} seconds`);
  console.log(`ğŸ“ Files processed: ${processedCount}`);
  console.log(`âš ï¸ Files skipped (constraint violation): ${skippedCount}`);



  process.exit(0);  // âœ… Exit script successfully
}

main();

/*
   node src/processFolder.single.js "D:\RU\RUImages"

   npm run single -- d:\
   npm run single -- D:\RU\RUImages
*/